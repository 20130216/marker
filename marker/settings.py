import os
import torch
from typing import Optional
from dotenv import load_dotenv
from pydantic import Field, computed_field
from pydantic_settings import BaseSettings
from enum import Enum

# ==================== åŸºç¡€é…ç½® ====================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

class LLMServiceType(str, Enum):
    OPENAI = "marker.services.openai.OpenAIService"

# ==================== åŠ è½½ç¯å¢ƒå˜é‡ ====================
def load_environment_variables():
    # ç¡®ä¿ .env è·¯å¾„ç»å¯¹æ­£ç¡®
    env_path = os.path.normpath(os.path.join(os.path.dirname(__file__), "..", "local.env"))
    print(f"ğŸ” æ­£åœ¨åŠ è½½ç¯å¢ƒæ–‡ä»¶: {env_path}")
    
    if os.path.exists(env_path):
        load_dotenv(env_path, override=True)
        print("âœ… æˆåŠŸåŠ è½½çš„ç¯å¢ƒå˜é‡:")
        print(f"OPENAI_MODEL={os.getenv('OPENAI_MODEL')}")
        print(f"OPENAI_API_KEY={os.getenv('OPENAI_API_KEY')}")
        print(f"OUTPUT_FORMAT={os.getenv('OUTPUT_FORMAT')}\n")
    else:
        raise FileNotFoundError(f"âŒ ç¯å¢ƒæ–‡ä»¶ä¸å­˜åœ¨: {env_path}")

# ==================== ä¸»é…ç½®ç±» ====================
class Settings(BaseSettings):
    # ----- è®¾ç½®è¿™ä¸ªé‡è¦çš„æ§åˆ¶æ¢çº½ï¼šUSE_LLMï¼›é»˜è®¤ä¸ç”¨ LLMï¼Œåªæœ‰æ˜ç¡®å†™ True æ‰ç”¨ -----    
    USE_LLM: bool = Field(
    default=False,
    description="æ˜¯å¦å¯ç”¨å¤§æ¨¡å‹ï¼ˆLLMï¼‰",
    env="USE_LLM"
    )
    
    # ----- æ ¸å¿ƒæœåŠ¡é…ç½® -----
    LLM_SERVICE: LLMServiceType = Field(
        default=LLMServiceType.OPENAI,
        description="Active LLM service provider",
        env="LLM_SERVICE"
    )

    # ----- OpenAI é…ç½® -----
    OPENAI_BASE_URL: str = Field(
        default="https://api.openai.com/v1",
        description="OpenAI API endpoint",
        env="OPENAI_BASE_URL"
    )
    
    OPENAI_API_KEY: Optional[str] = Field(
        default=None,
        description="OpenAI API key",
        env="OPENAI_API_KEY"
    )
    
    OPENAI_MODEL: str = Field(
        default="gpt-4.1",  # å¿…é¡»æä¾›å€¼
        description="æ¨¡å‹åç§° (å¦‚ gpt-4.1 æˆ– gemini-2.5-pro-exp-03-25)",
        env="OPENAI_MODEL"
    )
    # ----- æ–°å¢ å›¾ç‰‡æ ¼å¼é…ç½®å‚æ•° -----
    OUTPUT_IMAGE_FORMAT: str = Field(
        default="png",  # é»˜è®¤ä½¿ç”¨PNGæ ¼å¼
        description="Output image format (png/jpg/webp)",
        env="OUTPUT_IMAGE_FORMAT"
    )
    # ----- æ–°å¢ GOOGLE_API_KEY é…ç½® -----
    # GOOGLE_API_KEY: Optional[str] = Field(
    #     default=None,
    #     description="Google API key",
    #     env="GOOGLE_API_KEY"
    # )
    
        # ----- æ–°å¢ FONT_PATH é…ç½® -----
    FONT_PATH: str = Field(
        default= "/System/Library/Fonts/Supplemental/Arial Unicode.ttf",  # macOSä¸Šçš„Arial Unicodeå­—ä½“è·¯å¾„
        description="Font file path for text processing",
        env="FONT_PATH"
    )
    
    FONT_NAME: str = Field(
        default="Arial",
        description="Font name for text rendering",
        env="FONT_NAME"
    )    

    # ----- ç³»ç»Ÿé…ç½® -----
    OUTPUT_DIR: str = Field(
        default=os.path.join(BASE_DIR, "output"),
        description="Output directory",
        env="OUTPUT_DIR"
    )
    
    OUTPUT_FORMAT: str = Field(
        default="markdown",
        description="Output file format",
        env="OUTPUT_FORMAT"
    )
    
    DEBUG: bool = Field(
        default=False,
        description="Enable debug mode",
        env="DEBUG"
    )

    DEBUG_LEVEL: str = Field(
        default="info",
        description="è°ƒè¯•æ¨¡å¼: info|verbose|debug",
        env=" DEBUG_LEVEL"
    )
    # åœ¨Settingsç±»ä¸­æ·»åŠ ä»¥ä¸‹å­—æ®µ
    FORCE_OCR: bool = Field(
        default=False,
        description="å¼ºåˆ¶ä½¿ç”¨OCRå¤„ç†æ‰€æœ‰æ–‡æœ¬",
        env="FORCE_OCR"
    )

    PAGE_RANGE: str = Field(
        default="all",
        description="å¤„ç†çš„é¡µé¢èŒƒå›´(å¦‚'1-3')",
        env="PAGE_RANGE"
    )

    LANGUAGES: str = Field(
        default="en",
        description="æ–‡æ¡£è¯­è¨€ä»£ç (å¦‚'zh')",
        env="LANGUAGES"
    )

    MAX_RETRIES: int = Field(
        default=3,
        description="æœ€å¤§é‡è¯•æ¬¡æ•°",
        env="MAX_RETRIES"
    )


    # ==================== æ·»åŠ è®¡ç®—å±æ€§ï¼ˆ@computed_fieldï¼‰ ====================
    @computed_field
    @property
    def TORCH_DEVICE(self) -> str:
        if torch.cuda.is_available():
            return "cuda"
        if torch.backends.mps.is_available():
            return "mps"
        return "cpu"

    @computed_field
    @property
    def MODEL_DTYPE(self) -> torch.dtype:
        return torch.bfloat16 if self.TORCH_DEVICE == "cuda" else torch.float32


    @computed_field
    @property
    def TORCH_DEVICE(self) -> str:
        if torch.cuda.is_available():
            return "cuda"
        if torch.backends.mps.is_available():
            return "mps"
        return "cpu"

    @computed_field
    @property
    def TORCH_DEVICE_MODEL(self) -> str:
        """å…¼å®¹æ—§ä»£ç çš„åˆ«å"""
        return self.TORCH_DEVICE

    @computed_field
    @property
    def MODEL_DTYPE(self) -> torch.dtype:
        return torch.bfloat16 if self.TORCH_DEVICE == "cuda" else torch.float32
    # ==================== é…ç½®æºè®¾ç½® ====================
    class Config:
        extra = "ignore"


# marker/settings.py æœ€åæ·»åŠ 
settings = Settings()    

# ==================== æµ‹è¯•å‡½æ•° ====================
def validate_settings():
    """éªŒè¯é…ç½®åŠ è½½æ˜¯å¦æ­£ç¡®"""
    # å…ˆåŠ è½½ç¯å¢ƒå˜é‡
    load_environment_variables()
    
    # å®ä¾‹åŒ– Settings ç±»
    settings = Settings()
    
    print("\n" + "="*50)
    print("ğŸ” é…ç½®éªŒè¯ç»“æœ")
    print(f"LLM æœåŠ¡: {settings.LLM_SERVICE}")
    print(f"OpenAI æ¨¡å‹: {settings.OPENAI_MODEL}")
    print(f"API ç«¯ç‚¹: {settings.OPENAI_BASE_URL}")
    print(f"API å¯†é’¥: {'***'+settings.OPENAI_API_KEY[-3:] if settings.OPENAI_API_KEY else 'æœªè®¾ç½®'}")
    print(f"è¾“å‡ºç›®å½•: {settings.OUTPUT_DIR}")
    print(f"è®¡ç®—è®¾å¤‡: {settings.TORCH_DEVICE}")
    print("="*50 + "\n")

if __name__ == "__main__":
    validate_settings()
    
